# Text-Classification-and-Sentiment-Analysis-Machine-Learning-Project
Project used to learn how to use Support Vector Machines and Sentiment Analysis to classify data entries.

The dataset used for this project contains speeches from the UN General debates (1970 - 2017).

Database credit goes to https://github.com/blueprints-for-text-analytics-python/blueprints-text/tree/master/data/un-general-debates
__________________________________________________________________________________________________________________

## Text Classification
Using scikit-learn and NLTK I built a text processing and classifier pipeline to predict the country (USA or Canada) of a speech. I first filtered the dataframe to include only entries where country is USA or Canada Then I created a pipeline that first transforms the text data into TF-IDF vectors (term frequency â€“ inverse document frequency, a measure of importance of a word to a document in a collection adjusted for the fact that some words appear more frequently in general), then applies SVM (Support Vector Machine) to analyze data for classification while referencing a set of stop words to eliminate words that are widely used and carry very useful information for the purposes of this project.

The follwoing is the classification report generated by the model. 

<img width="427" alt="Screen Shot 2024-10-09 at 11 32 05 AM" src="https://github.com/user-attachments/assets/7f15ddc8-b7b0-4430-9f97-dc04563f0e01">


The rows of the classification report represent the classes (countries) being predicted.

Each row shows the following metrics
- Precision: The ratio of correctly predicted positive observations to the total predicted positives.
- Recall: The ratio of correctly predicted positive observations to all observations in the actual class.
- F1-score: The harmonic mean of precision and recall. It provides a balance between the two metrics.
- Support: The number of actual occurrences of each class in the dataset.

Given the overall statistics, the model performs well with an accuracy of 89%

The high precision but lower recall for Canadian speeches suggests that while the model rarely incorrectly labels something as Canadian (high precision), it sometimes misses actual Canadian speeches, labeling them as USA instead.

The model has perfect recall for USA speeches, meaning it captures all USA instances accurately. However, the precision for USA is slightly lower, indicating that some Canadian speeches were incorrectly classified as USA.


## Sentiment Analysis
